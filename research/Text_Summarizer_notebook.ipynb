{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"d74811abfd1047c7a78b48e04ee4acaf":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c8e30feaeb194a5ba8eb768a1d716da7","IPY_MODEL_03f1b41fac4e4ac49607def1e33cbed9","IPY_MODEL_40a6dd1a6f3d440fa3476c47ed57000f"],"layout":"IPY_MODEL_78400b4bedac481381041fe7332dbbcd"}},"c8e30feaeb194a5ba8eb768a1d716da7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3d28f3af503148658a4ab4358572b8e0","placeholder":"​","style":"IPY_MODEL_7e515d95e9ad46218782da0af16d3ced","value":"Filter: 100%"}},"03f1b41fac4e4ac49607def1e33cbed9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9d87205645424daa8d0c962eb9085a30","max":14732,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1734468886374c6fbd04b030e3d562f8","value":14732}},"40a6dd1a6f3d440fa3476c47ed57000f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4783ebf23acb4d55aa3f71781752cb42","placeholder":"​","style":"IPY_MODEL_7a98919276824da7be600b8dcb4a6a99","value":" 14732/14732 [00:00&lt;00:00, 147278.00 examples/s]"}},"78400b4bedac481381041fe7332dbbcd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3d28f3af503148658a4ab4358572b8e0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7e515d95e9ad46218782da0af16d3ced":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9d87205645424daa8d0c962eb9085a30":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1734468886374c6fbd04b030e3d562f8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4783ebf23acb4d55aa3f71781752cb42":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7a98919276824da7be600b8dcb4a6a99":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7970504681d84817b7daec9e28818fa6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2617976d94fb451ead005b311b5ebad7","IPY_MODEL_f0acb03f6e6c42ed8b22edbc681f5201","IPY_MODEL_a0e8ef70e73e48edbdca120153a6e3c1"],"layout":"IPY_MODEL_4d317a80688142d5abc1dba83a3f2659"}},"2617976d94fb451ead005b311b5ebad7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c8c5584f815b45dcb06cdab8f9b012da","placeholder":"​","style":"IPY_MODEL_edfa3988da874da69a1f4f2deb14f9e6","value":"Filter: 100%"}},"f0acb03f6e6c42ed8b22edbc681f5201":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7e6332cfbfb64cc6a924aaac98544eb6","max":818,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cbc4a82f7b404577be08ff21ddd61c7f","value":818}},"a0e8ef70e73e48edbdca120153a6e3c1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2f3db093eb7c49c9a62c9ff8754d529d","placeholder":"​","style":"IPY_MODEL_5a3f883ebae64a12abaff68736121a01","value":" 818/818 [00:00&lt;00:00, 28060.59 examples/s]"}},"4d317a80688142d5abc1dba83a3f2659":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c8c5584f815b45dcb06cdab8f9b012da":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"edfa3988da874da69a1f4f2deb14f9e6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7e6332cfbfb64cc6a924aaac98544eb6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cbc4a82f7b404577be08ff21ddd61c7f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2f3db093eb7c49c9a62c9ff8754d529d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5a3f883ebae64a12abaff68736121a01":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4d1b944ef11f480bb36d0cf3f2d242eb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_221db86b02934c46b4274d22c477e56d","IPY_MODEL_c4e161ae41614fd48b81ea5ab62a734b","IPY_MODEL_b52fbd87d4284baf8c47b16b254a5c68"],"layout":"IPY_MODEL_8b53ffead58045b39e3805f5823c7185"}},"221db86b02934c46b4274d22c477e56d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_46a4a71cae4042c098a9f20c17e274aa","placeholder":"​","style":"IPY_MODEL_ad2a8bc4681e4a58bc3658ebb509589f","value":"Filter: 100%"}},"c4e161ae41614fd48b81ea5ab62a734b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_07bf6d9f8ebb44f08e50ec12217e28da","max":819,"min":0,"orientation":"horizontal","style":"IPY_MODEL_eaa8f457fd914a77a1d4161eb077b861","value":819}},"b52fbd87d4284baf8c47b16b254a5c68":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c1dbced0b6c64caf9c881b68e0255196","placeholder":"​","style":"IPY_MODEL_63b9e04073ca47668b412ee5ccbcd3f8","value":" 819/819 [00:00&lt;00:00, 27887.12 examples/s]"}},"8b53ffead58045b39e3805f5823c7185":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"46a4a71cae4042c098a9f20c17e274aa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ad2a8bc4681e4a58bc3658ebb509589f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"07bf6d9f8ebb44f08e50ec12217e28da":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eaa8f457fd914a77a1d4161eb077b861":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c1dbced0b6c64caf9c881b68e0255196":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"63b9e04073ca47668b412ee5ccbcd3f8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"630d01d23afb426eb9dd1064fe80c3b5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5e7d71c96cbc4ac4aadc644477307ec9","IPY_MODEL_7050fedc93274ae7b90112cb14c59fd8","IPY_MODEL_9947d9b3694d436eb034c813f1153bb0"],"layout":"IPY_MODEL_2193d5ed4d5e49f4a87f343eb6a90c97"}},"5e7d71c96cbc4ac4aadc644477307ec9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_684e4a1450314b75aa684b496e4f9bda","placeholder":"​","style":"IPY_MODEL_cf7d2ed96cd64f0e86eeea37c82628be","value":"Map: 100%"}},"7050fedc93274ae7b90112cb14c59fd8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7c3049846bb64c15b35d6295aa97ea3b","max":14731,"min":0,"orientation":"horizontal","style":"IPY_MODEL_79d7c5e178de414d81e4a3fa3304cf97","value":14731}},"9947d9b3694d436eb034c813f1153bb0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4b6b5c3009f54e91aeec936586f5fa0c","placeholder":"​","style":"IPY_MODEL_3b96eb7fabf1487bbde3ab69ef134744","value":" 14731/14731 [00:13&lt;00:00, 1137.38 examples/s]"}},"2193d5ed4d5e49f4a87f343eb6a90c97":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"684e4a1450314b75aa684b496e4f9bda":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cf7d2ed96cd64f0e86eeea37c82628be":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7c3049846bb64c15b35d6295aa97ea3b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"79d7c5e178de414d81e4a3fa3304cf97":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4b6b5c3009f54e91aeec936586f5fa0c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3b96eb7fabf1487bbde3ab69ef134744":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3d34ae670ff347eba6bc15da8056f2b6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b9272ee969ee4d3ea6b59f0c693325ca","IPY_MODEL_840a9e285f0b4f07bcc67695099ef02a","IPY_MODEL_47a588ee796644a49263824f3f5962c6"],"layout":"IPY_MODEL_f95a7f0f571d487db03eca2a312ff565"}},"b9272ee969ee4d3ea6b59f0c693325ca":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d9d8063f21df40bb8384d02260d45d9e","placeholder":"​","style":"IPY_MODEL_3da3c8855a2d4378aa92ec359ebc9b55","value":"Map: 100%"}},"840a9e285f0b4f07bcc67695099ef02a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b45e41382dab4465ad0591b2131af996","max":818,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7276d9d24e044b6e839c288eeb290ceb","value":818}},"47a588ee796644a49263824f3f5962c6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4278545aa9a94aca9364240f510d99ea","placeholder":"​","style":"IPY_MODEL_658d1bc427d74b9db68450e5fc0c94a8","value":" 818/818 [00:00&lt;00:00, 1208.87 examples/s]"}},"f95a7f0f571d487db03eca2a312ff565":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d9d8063f21df40bb8384d02260d45d9e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3da3c8855a2d4378aa92ec359ebc9b55":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b45e41382dab4465ad0591b2131af996":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7276d9d24e044b6e839c288eeb290ceb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4278545aa9a94aca9364240f510d99ea":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"658d1bc427d74b9db68450e5fc0c94a8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c04b08bccc944c1d8a7a88c608c208c9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0ffa02d9f8564b50987d128050cd185d","IPY_MODEL_3afe7450a18240a9a8577c5b2e1206a9","IPY_MODEL_14476e006049488faf60a1b4747e4427"],"layout":"IPY_MODEL_e0b6415fd9814617bf355ba579e1ef94"}},"0ffa02d9f8564b50987d128050cd185d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dd4d757238124617a423c2b25f616681","placeholder":"​","style":"IPY_MODEL_38269dfa18ed4c82a896fe6aed6e1c30","value":"Map: 100%"}},"3afe7450a18240a9a8577c5b2e1206a9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1cce92bfcd8d44c7b53fe4228ae31947","max":819,"min":0,"orientation":"horizontal","style":"IPY_MODEL_06a8cba534ad4b67ae468bae50078fda","value":819}},"14476e006049488faf60a1b4747e4427":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_18ea847570e0489bb97e30d2167e1715","placeholder":"​","style":"IPY_MODEL_6a62d30564fe4801ae2db1b06203336c","value":" 819/819 [00:00&lt;00:00, 1141.80 examples/s]"}},"e0b6415fd9814617bf355ba579e1ef94":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dd4d757238124617a423c2b25f616681":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"38269dfa18ed4c82a896fe6aed6e1c30":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1cce92bfcd8d44c7b53fe4228ae31947":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"06a8cba534ad4b67ae468bae50078fda":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"18ea847570e0489bb97e30d2167e1715":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6a62d30564fe4801ae2db1b06203336c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31042,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!nvidia-smi","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R8yQhvOzqVlv","outputId":"d56ce96a-0cbd-4209-f329-b20a2a26e6f6","trusted":true,"execution":{"iopub.status.busy":"2025-07-06T08:44:18.480211Z","iopub.execute_input":"2025-07-06T08:44:18.480780Z","iopub.status.idle":"2025-07-06T08:44:18.678654Z","shell.execute_reply.started":"2025-07-06T08:44:18.480754Z","shell.execute_reply":"2025-07-06T08:44:18.677918Z"}},"outputs":[{"name":"stdout","text":"Sun Jul  6 08:44:18 2025       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  Tesla P100-PCIE-16GB           Off |   00000000:00:04.0 Off |                    0 |\n| N/A   35C    P0             25W /  250W |       3MiB /  16384MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n                                                                                         \n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n|  No running processes found                                                             |\n+-----------------------------------------------------------------------------------------+\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"!pip install transformers[sentencepiece] datasets sacrebleu rouge_score -q","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S_7VszqBqyL8","outputId":"860a642a-dd0d-4a4a-cdd8-7afe4f38c4c4","trusted":true,"execution":{"iopub.status.busy":"2025-07-06T08:44:18.680179Z","iopub.execute_input":"2025-07-06T08:44:18.680454Z","iopub.status.idle":"2025-07-06T08:44:25.478369Z","shell.execute_reply.started":"2025-07-06T08:44:18.680429Z","shell.execute_reply":"2025-07-06T08:44:25.477570Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\nbigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.9.0.13 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.4.0.6 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.10.19 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.7.4.40 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.9.5 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.9.41 which is incompatible.\ngcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"!pip install py7zr\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5lZkSCIkrJtC","outputId":"bdc3c048-ada8-494a-ef96-f9ccf9065bb2","trusted":true,"execution":{"iopub.status.busy":"2025-07-06T08:44:25.479489Z","iopub.execute_input":"2025-07-06T08:44:25.479706Z","iopub.status.idle":"2025-07-06T08:44:30.299669Z","shell.execute_reply.started":"2025-07-06T08:44:25.479683Z","shell.execute_reply":"2025-07-06T08:44:30.298934Z"}},"outputs":[{"name":"stdout","text":"Collecting py7zr\n  Downloading py7zr-1.0.0-py3-none-any.whl.metadata (17 kB)\nRequirement already satisfied: texttable in /usr/local/lib/python3.11/dist-packages (from py7zr) (1.7.0)\nRequirement already satisfied: pycryptodomex>=3.20.0 in /usr/local/lib/python3.11/dist-packages (from py7zr) (3.22.0)\nCollecting brotli>=1.1.0 (from py7zr)\n  Downloading Brotli-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from py7zr) (7.0.0)\nCollecting pyzstd>=0.16.1 (from py7zr)\n  Downloading pyzstd-0.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\nCollecting pyppmd<1.3.0,>=1.1.0 (from py7zr)\n  Downloading pyppmd-1.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.4 kB)\nCollecting pybcj<1.1.0,>=1.0.0 (from py7zr)\n  Downloading pybcj-1.0.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.7 kB)\nCollecting multivolumefile>=0.2.3 (from py7zr)\n  Downloading multivolumefile-0.2.3-py3-none-any.whl.metadata (6.3 kB)\nCollecting inflate64<1.1.0,>=1.0.0 (from py7zr)\n  Downloading inflate64-1.0.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.4 kB)\nRequirement already satisfied: typing-extensions>=4.13.2 in /usr/local/lib/python3.11/dist-packages (from pyzstd>=0.16.1->py7zr) (4.13.2)\nDownloading py7zr-1.0.0-py3-none-any.whl (69 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.7/69.7 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading Brotli-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m38.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading inflate64-1.0.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (96 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading multivolumefile-0.2.3-py3-none-any.whl (17 kB)\nDownloading pybcj-1.0.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (50 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pyppmd-1.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.3/141.3 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pyzstd-0.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (412 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m412.9/412.9 kB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: brotli, pyzstd, pyppmd, pybcj, multivolumefile, inflate64, py7zr\nSuccessfully installed brotli-1.1.0 inflate64-1.0.3 multivolumefile-0.2.3 py7zr-1.0.0 pybcj-1.0.6 pyppmd-1.2.0 pyzstd-0.17.0\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"!pip install --upgrade accelerate\n!pip install -y transformers accelerate\n!pip install transformers accelerate","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CbejiFxIr4lu","outputId":"361ac445-a4fa-438f-e74d-d9ce87b085c6","trusted":true,"execution":{"iopub.status.busy":"2025-07-06T08:44:30.301589Z","iopub.execute_input":"2025-07-06T08:44:30.301841Z","iopub.status.idle":"2025-07-06T08:45:44.950411Z","shell.execute_reply.started":"2025-07-06T08:44:30.301817Z","shell.execute_reply":"2025-07-06T08:45:44.949622Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.5.2)\nCollecting accelerate\n  Downloading accelerate-1.8.1-py3-none-any.whl.metadata (19 kB)\nRequirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.11/dist-packages (from accelerate) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (25.0)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (7.0.0)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate) (6.0.2)\nRequirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.6.0+cu124)\nRequirement already satisfied: huggingface_hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.31.1)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.5.3)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (3.18.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (2025.3.0)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (2.32.3)\nRequirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (4.67.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (4.13.2)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (1.1.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate) (2.4.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0.0,>=1.17->accelerate) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0.0,>=1.17->accelerate) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<3.0.0,>=1.17->accelerate) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<3.0.0,>=1.17->accelerate) (2024.2.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2025.4.26)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<3.0.0,>=1.17->accelerate) (2024.2.0)\nDownloading accelerate-1.8.1-py3-none-any.whl (365 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m365.3/365.3 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m77.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, accelerate\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.9.41\n    Uninstalling nvidia-nvjitlink-cu12-12.9.41:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.9.41\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.10.19\n    Uninstalling nvidia-curand-cu12-10.3.10.19:\n      Successfully uninstalled nvidia-curand-cu12-10.3.10.19\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.4.0.6\n    Uninstalling nvidia-cufft-cu12-11.4.0.6:\n      Successfully uninstalled nvidia-cufft-cu12-11.4.0.6\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.9.0.13\n    Uninstalling nvidia-cublas-cu12-12.9.0.13:\n      Successfully uninstalled nvidia-cublas-cu12-12.9.0.13\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.9.5\n    Uninstalling nvidia-cusparse-cu12-12.5.9.5:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.9.5\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.7.4.40\n    Uninstalling nvidia-cusolver-cu12-11.7.4.40:\n      Successfully uninstalled nvidia-cusolver-cu12-11.7.4.40\n  Attempting uninstall: accelerate\n    Found existing installation: accelerate 1.5.2\n    Uninstalling accelerate-1.5.2:\n      Successfully uninstalled accelerate-1.5.2\nSuccessfully installed accelerate-1.8.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n\nUsage:   \n  pip3 install [options] <requirement specifier> [package-index-options] ...\n  pip3 install [options] -r <requirements file> [package-index-options] ...\n  pip3 install [options] [-e] <vcs project url> ...\n  pip3 install [options] [-e] <local project path> ...\n  pip3 install [options] <archive url/path> ...\n\nno such option: -y\nRequirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\nRequirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.8.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.31.1)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (7.0.0)\nRequirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.6.0+cu124)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# !pip uninstall -y torchvision\n# !pip install torchvision --no-cache-dir --force-reinstall\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-06T08:45:44.951387Z","iopub.execute_input":"2025-07-06T08:45:44.951611Z","iopub.status.idle":"2025-07-06T08:45:44.955748Z","shell.execute_reply.started":"2025-07-06T08:45:44.951588Z","shell.execute_reply":"2025-07-06T08:45:44.955193Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"from transformers import pipeline, set_seed\nfrom datasets import load_dataset, load_from_disk\n\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n\nimport nltk\nfrom nltk.tokenize import sent_tokenize\n\nfrom tqdm import tqdm\nimport torch\n\nnltk.download(\"punkt\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RtgBBc3osPmf","outputId":"4d3a8915-7ce0-4d3e-cd94-57b8fd7696da","trusted":true,"execution":{"iopub.status.busy":"2025-07-06T08:45:44.956501Z","iopub.execute_input":"2025-07-06T08:45:44.956764Z","iopub.status.idle":"2025-07-06T08:45:45.853553Z","shell.execute_reply.started":"2025-07-06T08:45:44.956741Z","shell.execute_reply":"2025-07-06T08:45:45.852838Z"}},"outputs":[{"name":"stderr","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n","output_type":"stream"},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\ndevice","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"XTjQ3fzhuwG8","outputId":"e3423d77-83d6-4851-ab64-760693fdab12","trusted":true,"execution":{"iopub.status.busy":"2025-07-06T08:45:45.854301Z","iopub.execute_input":"2025-07-06T08:45:45.854633Z","iopub.status.idle":"2025-07-06T08:45:45.859741Z","shell.execute_reply.started":"2025-07-06T08:45:45.854615Z","shell.execute_reply":"2025-07-06T08:45:45.859057Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"'cuda'"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"model_ckpt = \"google/pegasus-cnn_dailymail\"\n\ntokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n\nmodel_pegasus = AutoModelForSeq2SeqLM.from_pretrained(model_ckpt).to(device)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1ls6hGhExIt0","outputId":"42a33d38-facb-489a-d39e-e6b2ae3ff4ff","trusted":true,"execution":{"iopub.status.busy":"2025-07-06T08:45:45.860528Z","iopub.execute_input":"2025-07-06T08:45:45.860841Z","iopub.status.idle":"2025-07-06T08:46:12.433866Z","shell.execute_reply.started":"2025-07-06T08:45:45.860819Z","shell.execute_reply":"2025-07-06T08:46:12.433281Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/88.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bfc3e2ca5dca45328dd5d7b00db0db32"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6c1bafe5b6a84a26a39da80b271265e6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/1.91M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a2618e2336a41049e90b2404a426a6f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/65.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f99951c9586647fd853e44b607abb0b8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/2.28G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"56fa2f597bc14a9690d45c9bf5022c5b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/2.28G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c57947ce7ffe429698a4460e5b2ffb08"}},"metadata":{}},{"name":"stderr","text":"Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-cnn_dailymail and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/280 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6cd6820f27444a6daf954686976f94c0"}},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"# !pip install -U datasets fsspec\n","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"NinIJRNj28D1","outputId":"321ae1da-31a9-4e7e-babf-70896baa2987","trusted":true,"execution":{"iopub.status.busy":"2025-07-06T08:46:12.434578Z","iopub.execute_input":"2025-07-06T08:46:12.434807Z","iopub.status.idle":"2025-07-06T08:46:12.438517Z","shell.execute_reply.started":"2025-07-06T08:46:12.434791Z","shell.execute_reply":"2025-07-06T08:46:12.437775Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"from datasets import load_dataset\n\nds = load_dataset(\"knkarthick/samsum\")\n\nds","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N36OaPa_xQfr","outputId":"eeb1ecda-1a5e-49fc-d9bf-5dc1ff350d46","trusted":true,"execution":{"iopub.status.busy":"2025-07-06T08:46:12.440825Z","iopub.execute_input":"2025-07-06T08:46:12.441024Z","iopub.status.idle":"2025-07-06T08:46:14.938849Z","shell.execute_reply.started":"2025-07-06T08:46:12.441009Z","shell.execute_reply":"2025-07-06T08:46:14.938092Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1cd9dd6a0f4042ee91c8e909298fde44"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train.csv: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8073c3d1ab0544bfae21c602520da7b1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"validation.csv: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"70809aefefd541b69dc136c5377701e9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test.csv: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8546eb1c2cbc498584e1ab1d2cb8bf27"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/14732 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"05d57a03c9784b598e1cccb4695fa251"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/818 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2626baf18f3d4549b1243ff9c7311ee1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/819 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e595d90041fd4f34be939e15c750f61f"}},"metadata":{}},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['id', 'dialogue', 'summary'],\n        num_rows: 14732\n    })\n    validation: Dataset({\n        features: ['id', 'dialogue', 'summary'],\n        num_rows: 818\n    })\n    test: Dataset({\n        features: ['id', 'dialogue', 'summary'],\n        num_rows: 819\n    })\n})"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"split_lengths = [len(ds[split])for split in ds]\n\nprint(f\"Split lengths: {split_lengths}\")\nprint(f\"Features: {ds['train'].column_names}\")\nprint(\"\\nDialogue:\")\n\nprint(ds[\"test\"][1][\"dialogue\"])\n\nprint(\"\\nSummary:\")\n\nprint(ds[\"test\"][1][\"summary\"])","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J27XUXLh2WQQ","outputId":"8ae9038c-d58f-4d5b-a6c5-22035d532fe4","trusted":true,"execution":{"iopub.status.busy":"2025-07-06T08:46:14.939672Z","iopub.execute_input":"2025-07-06T08:46:14.940494Z","iopub.status.idle":"2025-07-06T08:46:14.951336Z","shell.execute_reply.started":"2025-07-06T08:46:14.940468Z","shell.execute_reply":"2025-07-06T08:46:14.950432Z"}},"outputs":[{"name":"stdout","text":"Split lengths: [14732, 818, 819]\nFeatures: ['id', 'dialogue', 'summary']\n\nDialogue:\nEric: MACHINE!\nRob: That's so gr8!\nEric: I know! And shows how Americans see Russian ;)\nRob: And it's really funny!\nEric: I know! I especially like the train part!\nRob: Hahaha! No one talks to the machine like that!\nEric: Is this his only stand-up?\nRob: Idk. I'll check.\nEric: Sure.\nRob: Turns out no! There are some of his stand-ups on youtube.\nEric: Gr8! I'll watch them now!\nRob: Me too!\nEric: MACHINE!\nRob: MACHINE!\nEric: TTYL?\nRob: Sure :)\n\nSummary:\nEric and Rob are going to watch a stand-up on youtube.\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"print(ds)\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iVVwHSUyDn9u","outputId":"e9203cb6-d234-450b-a80c-58fb58980db3","trusted":true,"execution":{"iopub.status.busy":"2025-07-06T08:46:14.952003Z","iopub.execute_input":"2025-07-06T08:46:14.952280Z","iopub.status.idle":"2025-07-06T08:46:18.044061Z","shell.execute_reply.started":"2025-07-06T08:46:14.952256Z","shell.execute_reply":"2025-07-06T08:46:18.043287Z"}},"outputs":[{"name":"stdout","text":"DatasetDict({\n    train: Dataset({\n        features: ['id', 'dialogue', 'summary'],\n        num_rows: 14732\n    })\n    validation: Dataset({\n        features: ['id', 'dialogue', 'summary'],\n        num_rows: 818\n    })\n    test: Dataset({\n        features: ['id', 'dialogue', 'summary'],\n        num_rows: 819\n    })\n})\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"\ndef convert_examples_to_features(example_batch):\n    # Tokenize input (dialogue)\n    input_encodings = tokenizer(\n        example_batch['dialogue'],\n        max_length=1024,\n        truncation=True,\n        padding=\"max_length\"\n    )\n\n    # Tokenize target (summary) using `text_target`\n    target_encodings = tokenizer(\n        text_target=example_batch['summary'],\n        max_length=128,\n        truncation=True,\n        padding=\"max_length\"\n    )\n\n    return {\n        \"input_ids\": input_encodings[\"input_ids\"],\n        \"attention_mask\": input_encodings[\"attention_mask\"],\n        \"labels\": target_encodings[\"input_ids\"]\n    }\n","metadata":{"id":"uGRAdqfu6rbw","trusted":true,"execution":{"iopub.status.busy":"2025-07-06T08:46:18.044944Z","iopub.execute_input":"2025-07-06T08:46:18.045258Z","iopub.status.idle":"2025-07-06T08:46:18.819003Z","shell.execute_reply.started":"2025-07-06T08:46:18.045215Z","shell.execute_reply":"2025-07-06T08:46:18.818058Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"train_ds = ds['train']\n","metadata":{"id":"IxIqEu0TEWOU","trusted":true,"execution":{"iopub.status.busy":"2025-07-06T08:46:18.819889Z","iopub.execute_input":"2025-07-06T08:46:18.820123Z","iopub.status.idle":"2025-07-06T08:46:19.666320Z","shell.execute_reply.started":"2025-07-06T08:46:18.820103Z","shell.execute_reply":"2025-07-06T08:46:19.663660Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"# checking for null values\n\ndef is_valid(example):\n    return (\n        isinstance(example['dialogue'], str) and example['dialogue'].strip() != \"\" and\n        isinstance(example['summary'], str) and example['summary'].strip() != \"\"\n    )\n\n# Clean each split (train, validation, test)\ncleaned_ds = {}\nfor split in ds.keys():\n    cleaned_ds[split] = ds[split].filter(is_valid)\n\n# Optional: re-wrap into a DatasetDict\nfrom datasets import DatasetDict\nds_cleaned = DatasetDict(cleaned_ds)\n\n# Now check how many examples remain in each split\nprint(ds_cleaned)\n","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":356,"referenced_widgets":["d74811abfd1047c7a78b48e04ee4acaf","c8e30feaeb194a5ba8eb768a1d716da7","03f1b41fac4e4ac49607def1e33cbed9","40a6dd1a6f3d440fa3476c47ed57000f","78400b4bedac481381041fe7332dbbcd","3d28f3af503148658a4ab4358572b8e0","7e515d95e9ad46218782da0af16d3ced","9d87205645424daa8d0c962eb9085a30","1734468886374c6fbd04b030e3d562f8","4783ebf23acb4d55aa3f71781752cb42","7a98919276824da7be600b8dcb4a6a99","7970504681d84817b7daec9e28818fa6","2617976d94fb451ead005b311b5ebad7","f0acb03f6e6c42ed8b22edbc681f5201","a0e8ef70e73e48edbdca120153a6e3c1","4d317a80688142d5abc1dba83a3f2659","c8c5584f815b45dcb06cdab8f9b012da","edfa3988da874da69a1f4f2deb14f9e6","7e6332cfbfb64cc6a924aaac98544eb6","cbc4a82f7b404577be08ff21ddd61c7f","2f3db093eb7c49c9a62c9ff8754d529d","5a3f883ebae64a12abaff68736121a01","4d1b944ef11f480bb36d0cf3f2d242eb","221db86b02934c46b4274d22c477e56d","c4e161ae41614fd48b81ea5ab62a734b","b52fbd87d4284baf8c47b16b254a5c68","8b53ffead58045b39e3805f5823c7185","46a4a71cae4042c098a9f20c17e274aa","ad2a8bc4681e4a58bc3658ebb509589f","07bf6d9f8ebb44f08e50ec12217e28da","eaa8f457fd914a77a1d4161eb077b861","c1dbced0b6c64caf9c881b68e0255196","63b9e04073ca47668b412ee5ccbcd3f8"]},"id":"WlCJBVhXEXjB","outputId":"b993a569-5fc9-4fd7-ddfe-4e32529cd4f7","trusted":true,"execution":{"iopub.status.busy":"2025-07-06T08:46:19.667144Z","iopub.execute_input":"2025-07-06T08:46:19.667480Z","iopub.status.idle":"2025-07-06T08:46:20.894373Z","shell.execute_reply.started":"2025-07-06T08:46:19.667451Z","shell.execute_reply":"2025-07-06T08:46:20.893629Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/14732 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d60a829aa27344379c4a45d0e21799b1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/818 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2be6aac238e946e18b0d2302df03f134"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/819 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"56dd9a6e7ba64b74a01f04bf1eabea2a"}},"metadata":{}},{"name":"stdout","text":"DatasetDict({\n    train: Dataset({\n        features: ['id', 'dialogue', 'summary'],\n        num_rows: 14731\n    })\n    validation: Dataset({\n        features: ['id', 'dialogue', 'summary'],\n        num_rows: 818\n    })\n    test: Dataset({\n        features: ['id', 'dialogue', 'summary'],\n        num_rows: 819\n    })\n})\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"ds_pt = ds_cleaned.map(convert_examples_to_features, batched=True)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":113,"referenced_widgets":["630d01d23afb426eb9dd1064fe80c3b5","5e7d71c96cbc4ac4aadc644477307ec9","7050fedc93274ae7b90112cb14c59fd8","9947d9b3694d436eb034c813f1153bb0","2193d5ed4d5e49f4a87f343eb6a90c97","684e4a1450314b75aa684b496e4f9bda","cf7d2ed96cd64f0e86eeea37c82628be","7c3049846bb64c15b35d6295aa97ea3b","79d7c5e178de414d81e4a3fa3304cf97","4b6b5c3009f54e91aeec936586f5fa0c","3b96eb7fabf1487bbde3ab69ef134744","3d34ae670ff347eba6bc15da8056f2b6","b9272ee969ee4d3ea6b59f0c693325ca","840a9e285f0b4f07bcc67695099ef02a","47a588ee796644a49263824f3f5962c6","f95a7f0f571d487db03eca2a312ff565","d9d8063f21df40bb8384d02260d45d9e","3da3c8855a2d4378aa92ec359ebc9b55","b45e41382dab4465ad0591b2131af996","7276d9d24e044b6e839c288eeb290ceb","4278545aa9a94aca9364240f510d99ea","658d1bc427d74b9db68450e5fc0c94a8","c04b08bccc944c1d8a7a88c608c208c9","0ffa02d9f8564b50987d128050cd185d","3afe7450a18240a9a8577c5b2e1206a9","14476e006049488faf60a1b4747e4427","e0b6415fd9814617bf355ba579e1ef94","dd4d757238124617a423c2b25f616681","38269dfa18ed4c82a896fe6aed6e1c30","1cce92bfcd8d44c7b53fe4228ae31947","06a8cba534ad4b67ae468bae50078fda","18ea847570e0489bb97e30d2167e1715","6a62d30564fe4801ae2db1b06203336c"]},"id":"Ei3jDUF-8BQ5","outputId":"0fe0d846-8efc-4ac5-89c0-5923f8bb1c43","trusted":true,"execution":{"iopub.status.busy":"2025-07-06T08:46:20.895290Z","iopub.execute_input":"2025-07-06T08:46:20.895582Z","iopub.status.idle":"2025-07-06T08:46:32.715594Z","shell.execute_reply.started":"2025-07-06T08:46:20.895556Z","shell.execute_reply":"2025-07-06T08:46:32.715013Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/14731 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"433072a2a08047d3bdd1cde9b2b116ed"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/818 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7f19b16043af405694aca25393701ff7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/819 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1f659dfb637148a583dcc1923d4aba06"}},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"ds_pt[\"train\"]","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zPxHv2RV8OZj","outputId":"324cf4e5-5d73-479e-8340-7e088951aa75","trusted":true,"execution":{"iopub.status.busy":"2025-07-06T08:46:32.716537Z","iopub.execute_input":"2025-07-06T08:46:32.716829Z","iopub.status.idle":"2025-07-06T08:46:32.721497Z","shell.execute_reply.started":"2025-07-06T08:46:32.716804Z","shell.execute_reply":"2025-07-06T08:46:32.720762Z"}},"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['id', 'dialogue', 'summary', 'input_ids', 'attention_mask', 'labels'],\n    num_rows: 14731\n})"},"metadata":{}}],"execution_count":20},{"cell_type":"code","source":"# Training\n\nfrom transformers import DataCollatorForSeq2Seq\n\nseq2seq_data_collator = DataCollatorForSeq2Seq(tokenizer, model=model_pegasus)","metadata":{"id":"egg83DvsF7Va","trusted":true,"execution":{"iopub.status.busy":"2025-07-06T08:46:32.722180Z","iopub.execute_input":"2025-07-06T08:46:32.722450Z","iopub.status.idle":"2025-07-06T08:46:32.741940Z","shell.execute_reply.started":"2025-07-06T08:46:32.722427Z","shell.execute_reply":"2025-07-06T08:46:32.741271Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"from transformers import TrainingArguments\nprint(\"eval_strategy\" in TrainingArguments.__init__.__code__.co_varnames)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LwDH_cUVNQW6","outputId":"b3198897-ea2a-43e4-bbc2-3a7d0546a161","trusted":true,"execution":{"iopub.status.busy":"2025-07-06T08:46:32.742722Z","iopub.execute_input":"2025-07-06T08:46:32.742966Z","iopub.status.idle":"2025-07-06T08:46:32.756149Z","shell.execute_reply.started":"2025-07-06T08:46:32.742946Z","shell.execute_reply":"2025-07-06T08:46:32.755642Z"}},"outputs":[{"name":"stdout","text":"True\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"from transformers import TrainingArguments, Trainer\n\ntrainer_args = TrainingArguments(\n    output_dir='pegasus-samsum',\n    logging_steps=1,\n    save_steps=1000,\n    eval_steps=100,\n    eval_strategy='steps',\n    report_to='none',\n\n    per_device_train_batch_size=1,     \n    per_device_eval_batch_size=1,\n    gradient_accumulation_steps=8,\n\n    save_strategy = \"epoch\",\n\n    fp16=True,                         \n    bf16=False,\n    num_train_epochs=1,\n    warmup_steps=100,\n    weight_decay=0.01,\n)\n\n\n","metadata":{"id":"QW6ofHcpLivi","trusted":true,"execution":{"iopub.status.busy":"2025-07-06T08:46:32.756784Z","iopub.execute_input":"2025-07-06T08:46:32.757019Z","iopub.status.idle":"2025-07-06T08:46:32.799349Z","shell.execute_reply.started":"2025-07-06T08:46:32.757003Z","shell.execute_reply":"2025-07-06T08:46:32.798568Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"ds_for_train = ds_pt[\"train\"].select(range(3500))\n\ntrainer = Trainer(model=model_pegasus, args=trainer_args,\n                  tokenizer=tokenizer, data_collator=seq2seq_data_collator,\n                  train_dataset=ds_for_train,\n                  eval_dataset=ds_pt[\"validation\"])","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"duRE8QGgMQjb","outputId":"27062f57-a2c1-477b-824f-275b8fd21df4","trusted":true,"execution":{"iopub.status.busy":"2025-07-06T08:46:32.800106Z","iopub.execute_input":"2025-07-06T08:46:32.800384Z","iopub.status.idle":"2025-07-06T08:46:32.838293Z","shell.execute_reply.started":"2025-07-06T08:46:32.800362Z","shell.execute_reply":"2025-07-06T08:46:32.837540Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_35/1698747403.py:3: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(model=model_pegasus, args=trainer_args,\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"# import os\n# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"  # Or \"1\" to use the second GPU\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-06T08:46:32.839096Z","iopub.execute_input":"2025-07-06T08:46:32.839796Z","iopub.status.idle":"2025-07-06T08:46:32.842741Z","shell.execute_reply.started":"2025-07-06T08:46:32.839777Z","shell.execute_reply":"2025-07-06T08:46:32.842021Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"import torch\ntorch.cuda.empty_cache()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-06T08:46:32.843558Z","iopub.execute_input":"2025-07-06T08:46:32.843805Z","iopub.status.idle":"2025-07-06T08:46:32.857689Z","shell.execute_reply.started":"2025-07-06T08:46:32.843785Z","shell.execute_reply":"2025-07-06T08:46:32.857104Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"!nvidia-smi\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-06T08:46:32.858321Z","iopub.execute_input":"2025-07-06T08:46:32.858521Z","iopub.status.idle":"2025-07-06T08:46:33.143605Z","shell.execute_reply.started":"2025-07-06T08:46:32.858507Z","shell.execute_reply":"2025-07-06T08:46:33.142610Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Sun Jul  6 08:46:32 2025       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  Tesla P100-PCIE-16GB           Off |   00000000:00:04.0 Off |                    0 |\n| N/A   35C    P0             32W /  250W |    2445MiB /  16384MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n                                                                                         \n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n+-----------------------------------------------------------------------------------------+\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"print(torch.cuda.memory_summary())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-06T08:46:33.144749Z","iopub.execute_input":"2025-07-06T08:46:33.144995Z","iopub.status.idle":"2025-07-06T08:46:33.150731Z","shell.execute_reply.started":"2025-07-06T08:46:33.144961Z","shell.execute_reply":"2025-07-06T08:46:33.150078Z"}},"outputs":[{"name":"stdout","text":"|===========================================================================|\n|                  PyTorch CUDA memory summary, device ID 0                 |\n|---------------------------------------------------------------------------|\n|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n|===========================================================================|\n|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n|---------------------------------------------------------------------------|\n| Allocated memory      |   2178 MiB |   2178 MiB |   2178 MiB |      0 B   |\n|       from large pool |   2176 MiB |   2176 MiB |   2176 MiB |      0 B   |\n|       from small pool |      2 MiB |      2 MiB |      2 MiB |      0 B   |\n|---------------------------------------------------------------------------|\n| Active memory         |   2178 MiB |   2178 MiB |   2178 MiB |      0 B   |\n|       from large pool |   2176 MiB |   2176 MiB |   2176 MiB |      0 B   |\n|       from small pool |      2 MiB |      2 MiB |      2 MiB |      0 B   |\n|---------------------------------------------------------------------------|\n| Requested memory      |   2177 MiB |   2177 MiB |   2177 MiB |      0 B   |\n|       from large pool |   2175 MiB |   2175 MiB |   2175 MiB |      0 B   |\n|       from small pool |      2 MiB |      2 MiB |      2 MiB |      0 B   |\n|---------------------------------------------------------------------------|\n| GPU reserved memory   |   2188 MiB |   2188 MiB |   2188 MiB |      0 B   |\n|       from large pool |   2184 MiB |   2184 MiB |   2184 MiB |      0 B   |\n|       from small pool |      4 MiB |      4 MiB |      4 MiB |      0 B   |\n|---------------------------------------------------------------------------|\n| Non-releasable memory |   9848 KiB |  18380 KiB |    771 MiB | 780671 KiB |\n|       from large pool |   8192 KiB |  16384 KiB |    768 MiB | 778240 KiB |\n|       from small pool |   1656 KiB |   2044 KiB |      3 MiB |   2431 KiB |\n|---------------------------------------------------------------------------|\n| Allocations           |     680    |     680    |     680    |       0    |\n|       from large pool |     259    |     259    |     259    |       0    |\n|       from small pool |     421    |     421    |     421    |       0    |\n|---------------------------------------------------------------------------|\n| Active allocs         |     680    |     680    |     680    |       0    |\n|       from large pool |     259    |     259    |     259    |       0    |\n|       from small pool |     421    |     421    |     421    |       0    |\n|---------------------------------------------------------------------------|\n| GPU reserved segments |     104    |     104    |     104    |       0    |\n|       from large pool |     102    |     102    |     102    |       0    |\n|       from small pool |       2    |       2    |       2    |       0    |\n|---------------------------------------------------------------------------|\n| Non-releasable allocs |       2    |       2    |      50    |      48    |\n|       from large pool |       1    |       1    |      48    |      47    |\n|       from small pool |       1    |       1    |       2    |       1    |\n|---------------------------------------------------------------------------|\n| Oversize allocations  |       0    |       0    |       0    |       0    |\n|---------------------------------------------------------------------------|\n| Oversize GPU segments |       0    |       0    |       0    |       0    |\n|===========================================================================|\n\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"trainer.train()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"9RydyXclOheK","outputId":"82c19d69-2e11-4800-e193-381d11f38683","trusted":true,"execution":{"iopub.status.busy":"2025-07-06T08:46:33.151368Z","iopub.execute_input":"2025-07-06T08:46:33.151542Z","iopub.status.idle":"2025-07-06T09:21:52.444622Z","shell.execute_reply.started":"2025-07-06T08:46:33.151529Z","shell.execute_reply":"2025-07-06T09:21:52.443812Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='437' max='437' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [437/437 35:14, Epoch 0/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>100</td>\n      <td>8.852900</td>\n      <td>8.516949</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>5.636400</td>\n      <td>4.868847</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>1.375500</td>\n      <td>0.639359</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>0.558200</td>\n      <td>0.399347</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py:3339: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 128, 'min_length': 32, 'num_beams': 8, 'length_penalty': 0.8}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n  warnings.warn(\n","output_type":"stream"},{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=437, training_loss=4.989501616774762, metrics={'train_runtime': 2118.7404, 'train_samples_per_second': 1.652, 'train_steps_per_second': 0.206, 'total_flos': 1.0101567592071168e+16, 'train_loss': 4.989501616774762, 'epoch': 0.9988571428571429})"},"metadata":{}}],"execution_count":29},{"cell_type":"code","source":"# Evaluation\n\ndef generate_batch_sized_chunks(list_of_elements, batch_size):\n    \"\"\"split the dataset into smaller batches that we can process simultaneously\n    Yield successive batch-sized chunks from list_of_elements.\"\"\"\n    for i in range(0, len(list_of_elements), batch_size):\n        yield list_of_elements[i : i + batch_size]\n\n\n\ndef calculate_metric_on_test_ds(dataset, metric, model, tokenizer, \n                               batch_size=16, device=device, \n                               column_text=\"article\", \n                               column_summary=\"highlights\"):\n    article_batches = list(generate_batch_sized_chunks(dataset[column_text], batch_size))\n    target_batches = list(generate_batch_sized_chunks(dataset[column_summary], batch_size))\n\n    for article_batch, target_batch in tqdm(\n        zip(article_batches, target_batches), total=len(article_batches)):\n        \n        inputs = tokenizer(article_batch, max_length=1024,  truncation=True, \n                        padding=\"max_length\", return_tensors=\"pt\")\n        \n        summaries = model.generate(input_ids=inputs[\"input_ids\"].to(device),\n                         attention_mask=inputs[\"attention_mask\"].to(device), \n                         length_penalty=0.8, num_beams=8, max_length=128)\n        ''' parameter for length penalty ensures that the model does not generate sequences that are too long. '''\n        \n        # Finally, we decode the generated texts, \n        # replace the  token, and add the decoded texts with the references to the metric.\n        decoded_summaries = [tokenizer.decode(s, skip_special_tokens=True, \n                                clean_up_tokenization_spaces=True) \n               for s in summaries]      \n        \n        decoded_summaries = [d.replace(\"\", \" \") for d in decoded_summaries]\n        \n        \n        metric.add_batch(predictions=decoded_summaries, references=target_batch)\n        \n    #  Finally compute and return the ROUGE scores.\n    score = metric.compute()\n    return score","metadata":{"id":"jbfzDT9mOuJP","trusted":true,"execution":{"iopub.status.busy":"2025-07-06T09:21:52.445574Z","iopub.execute_input":"2025-07-06T09:21:52.445946Z","iopub.status.idle":"2025-07-06T09:21:52.453904Z","shell.execute_reply.started":"2025-07-06T09:21:52.445921Z","shell.execute_reply":"2025-07-06T09:21:52.453207Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"pip install evaluate\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-06T09:22:35.349366Z","iopub.execute_input":"2025-07-06T09:22:35.349882Z","iopub.status.idle":"2025-07-06T09:22:38.930577Z","shell.execute_reply.started":"2025-07-06T09:22:35.349858Z","shell.execute_reply":"2025-07-06T09:22:38.929746Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Collecting evaluate\n  Downloading evaluate-0.4.4-py3-none-any.whl.metadata (9.5 kB)\nRequirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.6.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from evaluate) (1.26.4)\nRequirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.3)\nRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.3)\nRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\nRequirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.3.0)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.31.1)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (25.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.18.0)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (19.0.1)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.11.18)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.13.2)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (1.1.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2025.4.26)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.6.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.4.3)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.20.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->evaluate) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->evaluate) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->evaluate) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->evaluate) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->evaluate) (2024.2.0)\nDownloading evaluate-0.4.4-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: evaluate\nSuccessfully installed evaluate-0.4.4\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"from evaluate import load\nrouge_names = [\"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\"]\nrouge_metric = load('rouge')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-06T09:22:44.868165Z","iopub.execute_input":"2025-07-06T09:22:44.868768Z","iopub.status.idle":"2025-07-06T09:22:45.302227Z","shell.execute_reply.started":"2025-07-06T09:22:44.868737Z","shell.execute_reply":"2025-07-06T09:22:45.301496Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9e1bc2b60c13426e8843a4b920192403"}},"metadata":{}}],"execution_count":33},{"cell_type":"code","source":"score = calculate_metric_on_test_ds(\n    ds['test'][0:10], rouge_metric, trainer.model, tokenizer, batch_size = 2, column_text = 'dialogue', column_summary= 'summary'\n)\n\nrouge_dict = dict((rn, score[rn]) for rn in rouge_names)\n\n\npd.DataFrame(rouge_dict, index = [f'pegasus'] )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-06T09:22:50.323487Z","iopub.execute_input":"2025-07-06T09:22:50.323954Z","iopub.status.idle":"2025-07-06T09:23:02.312899Z","shell.execute_reply.started":"2025-07-06T09:22:50.323927Z","shell.execute_reply":"2025-07-06T09:23:02.312293Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 5/5 [00:11<00:00,  2.36s/it]\n","output_type":"stream"},{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"           rouge1  rouge2    rougeL  rougeLsum\npegasus  0.025225     0.0  0.025189   0.025237","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>rouge1</th>\n      <th>rouge2</th>\n      <th>rougeL</th>\n      <th>rougeLsum</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>pegasus</th>\n      <td>0.025225</td>\n      <td>0.0</td>\n      <td>0.025189</td>\n      <td>0.025237</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":34},{"cell_type":"code","source":"## Save model\nmodel_pegasus.save_pretrained(\"pegasus-samsum-model\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-06T09:24:45.377108Z","iopub.execute_input":"2025-07-06T09:24:45.377421Z","iopub.status.idle":"2025-07-06T09:24:49.245182Z","shell.execute_reply.started":"2025-07-06T09:24:45.377400Z","shell.execute_reply":"2025-07-06T09:24:49.244612Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"## Save tokenizer\ntokenizer.save_pretrained(\"tokenizer\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-06T09:24:53.017163Z","iopub.execute_input":"2025-07-06T09:24:53.017469Z","iopub.status.idle":"2025-07-06T09:24:53.045740Z","shell.execute_reply.started":"2025-07-06T09:24:53.017447Z","shell.execute_reply":"2025-07-06T09:24:53.045006Z"}},"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"('tokenizer/tokenizer_config.json',\n 'tokenizer/special_tokens_map.json',\n 'tokenizer/spiece.model',\n 'tokenizer/added_tokens.json',\n 'tokenizer/tokenizer.json')"},"metadata":{}}],"execution_count":36},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained(\"tokenizer\", local_files_only=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-06T09:27:05.517083Z","iopub.execute_input":"2025-07-06T09:27:05.517738Z","iopub.status.idle":"2025-07-06T09:27:05.717973Z","shell.execute_reply.started":"2025-07-06T09:27:05.517712Z","shell.execute_reply":"2025-07-06T09:27:05.717423Z"}},"outputs":[],"execution_count":38},{"cell_type":"code","source":"#Prediction\n\ngen_kwargs = {\"length_penalty\": 0.8, \"num_beams\":8, \"max_length\": 128}\n\n\n\nsample_text = ds[\"test\"][0][\"dialogue\"]\n\nreference = ds[\"test\"][0][\"summary\"]\n\npipe = pipeline(\"summarization\", model=\"pegasus-samsum-model\",tokenizer=tokenizer)\n\n## \nprint(\"Dialogue:\")\nprint(sample_text)\n\n\n\nprint(\"\\nReference Summary:\")\nprint(reference)\n\n\nprint(\"\\nModel Summary:\")\nprint(pipe(sample_text, **gen_kwargs)[0][\"summary_text\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-06T09:27:57.818267Z","iopub.execute_input":"2025-07-06T09:27:57.818809Z","iopub.status.idle":"2025-07-06T09:27:59.852897Z","shell.execute_reply.started":"2025-07-06T09:27:57.818788Z","shell.execute_reply":"2025-07-06T09:27:59.852113Z"}},"outputs":[{"name":"stderr","text":"Device set to use cuda:0\nYour max_length is set to 128, but your input_length is only 122. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=61)\n","output_type":"stream"},{"name":"stdout","text":"Dialogue:\nHannah: Hey, do you have Betty's number?\nAmanda: Lemme check\nHannah: <file_gif>\nAmanda: Sorry, can't find it.\nAmanda: Ask Larry\nAmanda: He called her last time we were at the park together\nHannah: I don't know him well\nHannah: <file_gif>\nAmanda: Don't be shy, he's very nice\nHannah: If you say so..\nHannah: I'd rather you texted him\nAmanda: Just text him 🙂\nHannah: Urgh.. Alright\nHannah: Bye\nAmanda: Bye bye\n\nReference Summary:\nHannah needs Betty's number but Amanda doesn't have it. She needs to contact Larry.\n\nModel Summary:\nAmanda can't find Betty's number. She'll ask Larry to call her. Hannah will text him. She'd rather she text him.\n","output_type":"stream"}],"execution_count":40},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}